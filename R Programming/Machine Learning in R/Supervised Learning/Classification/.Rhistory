carseats = read.csv(file.choose(), header = TRUE)
# Emploratory data analysis
str(carseats)
summary(carseats)
# Converting categorical variables to factor
carseats$Sales = as.factor(carseats$Sales)
carseats$ShelveLoc = as.factor(carseats$ShelveLoc)
carseats$Urban = as.factor(carseats$Urban)
carseats$US = as.factor(carseats$US)
str(carseats)
summary(carseats)
plot(carseats)
str(carseats)
summary(carseats[,c(-1,-7,-10,-11)])
plot(carseats[,c(-1,-7,-10,-11)])
str(carseats)
data = read.csv(file.choose(), header = T)
set.seed(100) # to control randomness and get similar results
train = sample(1:400, 300)
test = -train
training_data = carsales[train,]
testing_data = carsales[test,]
carsales = read.csv(file.choose(), header = T)
set.seed(100) # to control randomness and get similar results
train = sample(1:400, 300)
test = -train
training_data = carsales[train,]
testing_data = carsales[test,]
model = glm(Sales ~.,data = training_data, family = binomial(link="logit"))
model
library(car)
vif(model)
corr_matrix = round(cor(training_data[,c(-1,-7,-10,-11)]),2)
corr_matrix
library(corrplot)
corrplot(corr_matrix, order = "hclust")
model.log = glm(Sales ~ CompPrice + Income + Advertising + Price + ShelveLoc + Age,
data = training_data,
family = binomial(link = "logit"))
summary(model.log)
logistic_probs = predict(model_2, testing_data, type = "response")
logistic_probs = predict(model.log, testing_data, type = "response")
for(i in 1:100){
if (logistic_probs[i] >= 0.500){
logistic_probs[i] = 1
}
if (logistic_probs[i] < 0.500){
logistic_probs[i] = 0
}
}
library(caret)
confusionMatrix(testing_data$Sales, logistic_probs)
#install.packages("caret")
data <- read.csv(file.choose(),header = T)
#Predictor Variables
Age <- data$Age
# REsponse Variable
choice <- data$Choice
#Regression Model
model_1 <- multinom(choice ~ Age, data = data)
library(nnet)
model_1 <- multinom(choice ~ Age, data = data)
library(nnet)
# Read the data from CSV
data <- read.csv(file.choose(),header = T)
#Predictor Variables
Age <- data$Age
# REsponse Variable
choice <- data$Choice
#Regression Model
model_1 <- multinom(choice ~ Age, data = data)
summary(model_1)
# Logistic REgression Example 2
# Read the data from CSV
data2 <- read.csv(file.choose(),header = T)
str(data2)
#Regression Model
model_2 <- multinom(data2$Loan.approval ~ Age+Salary, data = data2)
summary(model_2)
data = read.csv(file.choose(), header = TRUE)
set.seed(100) # to control randomness and get similar results
train = sample(1:23, 15)
test = -train
training_data = data[train,]
testing_data = data[test,]
library(nnet)
model_2 = multinom(training_data$Loan.approval ~ Age+Salary, data = data)
set.seed(100) # to control randomness and get similar results
train = sample(1:23, 15)
test = -train
training_data = data[train,]
testing_data = data[test,]
library(nnet)
model_2 = multinom(Loan.approval ~ Age+Salary, data = training_data)
lp = predict(model_2, testing_data)
library(caret)
confusionMatrix(testing_data$Loan.approval, lp)
### LOGISTIC REGRESSION ###
puffinbill <- read.csv(file.choose(), header = T)
head(puffinbill)
str(puffinbill)
# Creating New Variables
sex <- puffinbill$sex
curlen <- puffinbill$curlen
# Coding Female as 1 and Male as 0
sexcode <- ifelse(sex == "F", 1, 0)
# Plotting the Data
plot(curlen, jitter(x = sexcode, factor = 0.15), pch = 19,
xlab = "Curvature Length", ylab = "Sex (0 - Male, 1 - Female)")
# Logistic Regression Model
model <- glm(sexcode ~ curlen, binomial)
model
summary(model)
# Creating a sequence from minimum to maximum Curvature Length in steps of 0.01
xv <- seq(min(curlen), max(curlen), 0.01)
# Predicting the values for the given xv values
ypredict <- predict(model, list(curlen = xv), type = "response")
lines(xv, ypredict, col ="red")
# Some other plots
library(popbio)
logi.hist.plot(curlen, sexcode, boxp = F, type = "count", col = "gray",
xlabel = "size")
library(nnet)
# Read the data from CSV
data <- read.csv(file.choose(),header = T)
#Predictor Variables
Age <- data$Age
# REsponse Variable
choice <- data$Choice
library(popbio)
logi.hist.plot(data$Salary, data$Loan.approval, boxp = F, type = "count", col = "gray",
xlabel = "size")
logi.hist.plot(Age, data$Loan.approval, boxp = F, type = "count", col = "gray",
xlabel = "size")
plot(Age, jitter(x = data$Loan.approval, factor = 0.15), pch = 19,
xlab = "Curvature Length", ylab = "Sex (0 - Male, 1 - Female)")
str(data)
plot(data$Age, jitter(x = data$Loan.approval, factor = 0.15), pch = 19,
xlab = "Curvature Length", ylab = "Sex (0 - Male, 1 - Female)")
library(textir)
library(MASS)
data(fgl)
fgl
str(fgl$type)
#boxplot(RI ~ type, data = fgl)
par(mfrow = c(3,3), mai = c(.3,.6,.1,.1))
plot(RI ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Na ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Mg ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Al ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Si ~ type, data = fgl, col = c(grey(.2),2:6))
plot(K ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Ca ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Ba ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Fe ~ type, data = fgl, col = c(grey(.2),2:6))
## for illustration, consider the RIxAI plane
## use nt=200 training cases to find the nearest neighbors for
## the remaining 14 cases. These 14 cases become the evaluation
## (test, hold-out) cases
n = length(fgl$type)
nt = 200
set.seed(1)
# to make the calculations reproducible in repeated runs
train <- sample(1:n, nt)
## Standardization of the data is preferrable, especially if
## units of the features are quite different
## could do this from scratch by calculating the mean and
## standard deviation of each feature, and use those to standardize
## Even simpler, use the normalize function in the R package textir;
## it converts the data frame column to mean 0 and sd 1
x <- scale(fgl[,c(4,1)])
x[1:3,]
library(class)
nearest1 <- knn(train = x[train,], test = x[-train,], cl=fgl$type[train], k=1)
nearest5 <- knn(train = x[train,], test = x[-train,], cl=fgl$type[train], k=5)
data.frame(fgl$type[-train],nearest1,nearest5)
# plot to see how it worked on the training set
par(mfrow = c(1,2))
# plot for k=1 (single) nearest neighbor
plot(x[train,],col = fgl$type[train], cex = 0.8, main = "1-nearest neighbor")
points(x[-train],bg=nearest1,pch=21, col=grey(.9),cex = 1.25)
# plot for k=5 nearest neighbor
plot(x[train,],col = fgl$type[train], cex = 0.8, main = "5-nearest neighbor")
points(x[-train],bg=nearest5,pch=21, col=grey(.9),cex = 1.25)
legend("topright",legend = levels(fgl$type), fill=1:6, bty="n",cex=.75)
# calculate the proportion of correct classification on this one trainig set
ppcorn1 = 100*sum(fgl$type[-train]==nearest1)/(n-nt)
ppcorn5 = 100*sum(fgl$type[-train]==nearest5)/(n-nt)
ppcorn1
ppcorn5
str(fgl$type)
str(flg)
str(fgl)
data = Caravan
library(ISLR)
data = Caravan
str(data)
## we need to make sure that our data is scaled or standardized
# the first 2 variables have very different ranges, and that proves why we need to standardize.
var(data[,1])
var(data[,2])
?fgl
str(fgl)
x <- scale(fgl[,c(4,1)])
x[1:3,]
caret
library(caret)
library(MASS)
type = fgl[,10]
std_fgl = scale(fgl[,-10])
set.seed(1)
test = sample(1:214,170)
train = -test
training_data = std_fgl[train,]
testing_data = std_fgl[test,]
type = fgl[,10] # save the type column in a seperate variable
testing_y = type[test]
training_y = type[train]
library(FNN)
predicted_y = knn(training_data,testing_data,training_y,k=1)
head(predicted_y)
library(caret)
confusionMatrix(testing_y,predicted_y)
MSE = NULL
for(i in 1:7){
set.seed(1)
predicted_y = knn(training_data,testing_data,training_y,k=i)
MSE[i] = mean(predicted_y != testing_y)
print(i)
print(table(testing_y,predicted_y))
}
MSE
}
type = fgl[,10]
type
str(fgl)
str(fgl$type)
summary(fgl$type)
testing_y
training_y
library(MASS)
summary(fgl$type)
type = fgl[,10]
std_fgl = scale(fgl[,-10])
set.seed(1)
test = sample(1:214,170)
train = -test
training_data = std_fgl[train,]
testing_data = std_fgl[test,]
type = fgl[,10] # save the type column in a seperate variable
testing_y = type[test]
training_y = type[train]
library(FNN)
predicted_y = knn(training_data,testing_data,training_y,k=1)
head(predicted_y)
library(caret)
confusionMatrix(testing_y,predicted_y)
round(5.333,2)
summary(fgl$type)
type = fgl[,10]
std_fgl = scale(fgl[,-10])
set.seed(1)
test = sample(1:214,150)
train = -test
training_data = std_fgl[train,]
testing_data = std_fgl[test,]
type = fgl[,10] # save the type column in a seperate variable
testing_y = type[test]
training_y = type[train]
library(FNN)
predicted_y = knn(training_data,testing_data,training_y,k=1)
head(predicted_y)
library(caret)
confusionMatrix(testing_y,predicted_y)
library(MASS)
summary(fgl$type)
type = fgl[,10]
std_fgl = scale(fgl[,-10])
set.seed(1)
test = sample(1:214,150)
train = -test
training_data = std_fgl[train,]
testing_data = std_fgl[test,]
type = fgl[,10] # save the type column in a seperate variable
testing_y = type[test]
training_y = type[train]
library(FNN)
predicted_y = knn(training_data,testing_data,training_y,k=1)
head(predicted_y)
library(caret)
confusionMatrix(testing_y,predicted_y)
ME = NULL
for(i in 1:7){
set.seed(1)
predicted_y = knn(training_data,testing_data,training_y,k=i)
ME[i] = mean(predicted_y != testing_y)
print(i)
print(table(testing_y,predicted_y))
print (round(ME,3))
ME = NULL
cat("\n")
}
ME = NULL
for(i in 1:7){
set.seed(1)
predicted_y = knn(training_data,testing_data,training_y,k=i)
ME[i] = mean(predicted_y != testing_y)
print(i)
print(table(testing_y,predicted_y))
cat("\n")
}
print (round(ME,3))
library(textir)
library(MASS)
data(fgl)
?fgl
str(fgl$type)
str(fgl)
#boxplot(RI ~ type, data = fgl)
par(mfrow = c(3,3), mai = c(.3,.6,.1,.1))
plot(RI ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Na ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Mg ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Al ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Si ~ type, data = fgl, col = c(grey(.2),2:6))
plot(K ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Ca ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Ba ~ type, data = fgl, col = c(grey(.2),2:6))
plot(Fe ~ type, data = fgl, col = c(grey(.2),2:6))
## for illustration, consider the RIxAI plane
## use nt=200 training cases to find the nearest neighbors for
## the remaining 14 cases. These 14 cases become the evaluation
## (test, hold-out) cases
n = length(fgl$type)
nt = 200
set.seed(1)
# to make the calculations reproducible in repeated runs
train <- sample(1:n, nt)
## Standardization of the data is preferrable, especially if
## units of the features are quite different
## could do this from scratch by calculating the mean and
## standard deviation of each feature, and use those to standardize
## Even simpler, use the normalize function in the R package textir;
## it converts the data frame column to mean 0 and sd 1
x <- scale(fgl[,c(4,1)])
x[1:3,]
library(class)
nearest1 <- knn(train = x[train,], test = x[-train,], cl=fgl$type[train], k=1)
nearest5 <- knn(train = x[train,], test = x[-train,], cl=fgl$type[train], k=5)
data.frame(fgl$type[-train],nearest1,nearest5)
# plot to see how it worked on the training set
par(mfrow = c(1,2))
# plot for k=1 (single) nearest neighbor
plot(x[train,],col = fgl$type[train], cex = 0.8, main = "1-nearest neighbor")
points(x[-train],bg=nearest1,pch=21, col=grey(.9),cex = 1.25)
# plot for k=5 nearest neighbor
plot(x[train,],col = fgl$type[train], cex = 0.8, main = "5-nearest neighbor")
points(x[-train],bg=nearest5,pch=21, col=grey(.9),cex = 1.25)
legend("topright",legend = levels(fgl$type), fill=1:6, bty="n",cex=.75)
# calculate the proportion of correct classification on this one trainig set
ppcorn1 = 100*sum(fgl$type[-train]==nearest1)/(n-nt)
ppcorn5 = 100*sum(fgl$type[-train]==nearest5)/(n-nt)
ppcorn1
ppcorn5
library(MASS)
summary(fgl$type)
type = fgl[,10]
std_fgl = scale(fgl[,-10])
set.seed(1)
test = sample(1:214,150)
train = -test
training_data = std_fgl[train,]
testing_data = std_fgl[test,]
type = fgl[,10] # save the type column in a seperate variable
testing_y = type[test]
training_y = type[train]
library(FNN)
predicted_y = knn(training_data,testing_data,training_y,k=1)
head(predicted_y)
library(caret)
confusionMatrix(testing_y,predicted_y)
ME = NULL
for(i in 1:7){
set.seed(1)
predicted_y = knn(training_data,testing_data,training_y,k=i)
ME[i] = mean(predicted_y != testing_y)
print(i)
print(table(testing_y,predicted_y))
cat("\n")
}
print (round(ME,3))
min_error_rate = min(ME)
K = which(ME == min_error_rate)
print(min_error_rate)
print (K)
credit = read.csv(file.choose(), header = T)
credit$default = as.factor(credit$default)
set.seed(100) # to control randomness and get similar results
train = sample(1:1000, 800)
test = -train
training_data = credit[train, ]
testing_data = credit[test, ]
library(randomForest)
model = randomForest(medv ~ ., data = training_data, mtry = 6, importance = TRUE)
model = randomForest(default ~ ., data = training_data, mtry = 6, importance = TRUE)
model
plot(model$err.rate)
?plot.randomForest
plot(model$err.rate, type = "l")
plot(model$err.rate, type = "l", log = "y")
names(model)
model$err.rate
model$oob.times
plot(y = model$err.rate)
plot(model)
plot(model$err.rate)
plot(model$oob.times, type = "l")
model$ntree
plot(x = 1:500, y = model$err.rate)
length(model$err.rate)
length(model$oob.times)
plot(x = 1:1500, y = model$err.rate)
plot(model)
plot(x = 1:1500, y = model$err.rate)
plot(model$err.rate)
plot(model)
plot(model$err.rate)
names(model)
plot(model$inbag)
install.packages("ROCR")
predicted_y = predict(model, testing_data)
OOB.votes = predict(model,testing_data,type="prob");
OOB.pred <- OOB.votes[,2];
pred.obj <- prediction(OOB.pred,data = training_data);
library(ROCR)
pred.obj <- prediction(OOB.pred,data = training_data);
pred.obj <- prediction(OOB.pred);
pred.obj <- prediction(OOB.pred,training_data);
pred.obj <- prediction(OOB.pred,testing_data);
model
pred.obj <- prediction(OOB.pred,testing_data$default);
RP.perf <- performance(pred.obj, "rec","prec");
plot (RP.perf);
ROC.perf <- performance(pred.obj, "fpr","tpr");
plot (ROC.perf);
plot  (RP.perf@alpha.values[[1]],RP.perf@x.values[[1]]);
lines (RP.perf@alpha.values[[1]],RP.perf@y.values[[1]]);
lines (ROC.perf@alpha.values[[1]],ROC.perf@x.values[[1]]);
plot  (RP.perf@alpha.values[[1]],RP.perf@model.values[[1]]);
plot  (RP.perf@alpha.values[[1]])#,RP.perf@x.values[[1]]);
lines (RP.perf@alpha.values[[1]])#,RP.perf@y.values[[1]]);
plot  (RP.perf@alpha.values[[1]])#,RP.perf@x.values[[1]]);
lines (RP.perf@alpha.values[[1]])#,RP.perf@y.values[[1]]);
lines (ROC.perf@alpha.values[[1]])#,ROC.perf@x.values[[1]]);
plot(model)
layout(matrix(c(1,2),nrow=1),
width=c(4,1))
par(mar=c(5,4,4,0)) #No margin on the right side
plot(model, log="y")
par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("top", colnames(model$err.rate),col=1:4,cex=0.8,fill=1:4)
layout(matrix(c(1,2),nrow=1),
width=c(4,1))
#par(mar=c(5,4,4,0)) #No margin on the right side
plot(model, log="y")
par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("top", colnames(model$err.rate),col=1:4,cex=0.8,fill=1:4)
layout(matrix(c(1,2),nrow=1),
width=c(4,1))
par(mar=c(5,4,4,0)) #No margin on the right side
plot(model, log="y")
#par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("top", colnames(model$err.rate),col=1:4,cex=0.8,fill=1:4)
layout(matrix(c(1,2),nrow=1),
width=c(4,1))
par(mar=c(5,4,4,0)) #No margin on the right side
plot(model, log="y")
par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("top", colnames(model$err.rate),col=1:4,cex=0.8,fill=1:4)
layout(matrix(c(1, 2), nrow = 1), width = c(4, 1))
par(mar = c(5, 4, 4, 0)) #No margin on the right side
plot(model, main = "Random Forest Model")
par(mar = c(5, 0, 4, 2)) #No margin on the left side
plot(c(0, 1), type = "n", axes = F, xlab = "", ylab = "")
legend("top", colnames(model$err.rate), col = 1:3, cex = 0.8, fill = 1:3)
layout(matrix(c(1, 2), nrow = 1), width = c(4, 1))
par(mar = c(5, 4, 4, 0)) #No margin on the right side
plot(model, main = "Random Forest Model")
par(mar = c(5, 0, 4, 2)) #No margin on the left side
plot(c(0, 1), type = "n", axes = F, xlab = "", ylab = "")
legend("top", colnames(model$err.rate), col = 1:3, cex = 0.8, fill = 1:3)
imp = importance(model)[,1]
sort(imp, decreasing = TRUE)
sort(imp, decreasing = TRUE)
barplot(sort(imp),
col = "red",
main = "Variable Importance Plot",
ylim = c(0,20),
ylab = "% Increase MSE if Variable is Removed")
summary(getTree(model, k = 1, labelVar = TRUE))
predicted_y = predict(model, testing_data)
library(caret)
confusionMatrix(testing_data$default, predicted_y)
length(OOB.pred)
pred.obj = prediction(OOB.pred, testing_data$default);
RP.perf <- performance(pred.obj, "recall","precision");
RP.perf <- performance(pred.obj, "rec","prec");
plot (RP.perf);
